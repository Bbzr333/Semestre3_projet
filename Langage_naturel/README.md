# Pipeline de Classification des Relations SÃ©mantiques

Classification automatique des relations sÃ©mantiques dans les constructions gÃ©nitives franÃ§aises ("A de B").

## ğŸ“‹ Description

Ce projet dÃ©veloppe un systÃ¨me capable d'identifier automatiquement le type de relation sÃ©mantique entre deux noms dans une construction gÃ©nitive franÃ§aise.

**Exemples** : 
- "la porte de la maison" â†’ **r_holo** (Partie-Tout)
- "le livre de Marie" â†’ **r_own-1** (Possession)
- "le train de Paris" â†’ **r_lieu>origine** (Origine)

## ğŸ¯ Objectifs

- âœ… Classifier 15 types de relations sÃ©mantiques
- âœ… Comparer diffÃ©rentes approches (ML classique, deep learning)
- âœ… Ã‰valuer les performances face aux LLM
- âš™ï¸ Exploiter la ressource JeuxDeMots pour l'enrichissement

## ğŸ—‚ï¸ Structure du Projet

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Corpus initial (2250 exemples)
â”‚   â””â”€â”€ processed/              # DonnÃ©es prÃ©traitÃ©es (train/val/test)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/          # Nettoyage et normalisation
â”‚   â”œâ”€â”€ features/               # Extraction de features
â”‚   â”œâ”€â”€ models/                 # ModÃ¨les de classification
â”‚   â””â”€â”€ evaluation/             # MÃ©triques et analyse
â”œâ”€â”€ models/
â”‚   â””â”€â”€ baseline/               # ModÃ¨les entraÃ®nÃ©s (.joblib)
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ test_results.csv        # RÃ©sultats sur test set
â”‚   â”œâ”€â”€ cross_validation_detailed.csv
â”‚   â””â”€â”€ plots/                  # Visualisations
â”œâ”€â”€ run_preprocessing.py        # PrÃ©traitement du corpus
â”œâ”€â”€ run_feature_extraction.py  # Extraction de features
â”œâ”€â”€ run_train_baseline.py      # EntraÃ®nement des modÃ¨les
â”œâ”€â”€ run_evaluate_test.py       # Ã‰valuation sur test set
â”œâ”€â”€ run_cross_validation.py    # Validation croisÃ©e 10-fold
â””â”€â”€ run_chatgpt_simple.py      # Comparaison avec ChatGPT
```

## ğŸš€ Installation

```bash
# Cloner le dÃ©pÃ´t
git clone https://github.com/Bbzr333/Semestre3_projet
cd Langage_naturel

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirements.txt
```

## ğŸ“Š Types de Relations (15)

| Code | Description | Exemple |
|------|-------------|---------|
| `r_has_causatif` | Relation de cause | "les retards de la pluie" |
| `r_has_property-1` | PropriÃ©tÃ© | "la gÃ©nÃ©rositÃ© du bÃ©nÃ©vole" |
| `r_objet>matiere` | MatiÃ¨re | "une table de bois" |
| `r_lieu>origine` | Origine gÃ©ographique | "le vin de Bordeaux" |
| `r_topic` | ThÃ¨me/Sujet | "un livre d'histoire" |
| `r_depic` | ReprÃ©sentation | "le portrait de Marie" |
| `r_holo` | Partie-Tout | "la porte de la maison" |
| `r_lieu` | Localisation | "les gens de la ville" |
| `r_processus_agent` | Agent d'un processus | "le discours du prÃ©sident" |
| `r_processus_patient` | Patient d'un processus | "la sculpture du bois" |
| `r_processus>instr-1` | Instrument | "le marteau de forgeron" |
| `r_own-1` | Possession | "le livre de Marie" |
| `r_quantificateur` | QuantitÃ© | "un kilo de pommes" |
| `r_social_tie` | Lien social | "l'ami de Pierre" |
| `r_product_of` | Produit de | "le tableau de Picasso" |

## ğŸ”§ Utilisation

### Pipeline Complet

```bash
# 1. PrÃ©traitement du corpus
python run_preprocessing.py
# â†’ GÃ©nÃ¨re: data/processed/corpus_preprocessed.csv

# 2. Extraction de features
python run_feature_extraction.py
# â†’ GÃ©nÃ¨re: data/processed/{train,val,test}.csv

# 3. EntraÃ®nement des modÃ¨les
python run_train_baseline.py
# â†’ GÃ©nÃ¨re: models/baseline/*.joblib

# 4. Ã‰valuation sur test set
python run_evaluate_test.py
# â†’ GÃ©nÃ¨re: results/test_results.csv + matrices de confusion

# 5. Validation croisÃ©e
python run_cross_validation.py
# â†’ GÃ©nÃ¨re: results/cross_validation_detailed.csv

# 6. Comparaison avec ChatGPT (optionnel)
export OPENAI_API_KEY='sk-...'
python run_chatgpt_simple.py
# â†’ CoÃ»t: ~$0.10 pour 50 exemples
```

### Utilisation du Meilleur ModÃ¨le

```python
from src.models.baseline_models import BaselineClassifier
import pandas as pd

# Charger le modÃ¨le
model = BaselineClassifier.load('models/baseline/random_forest.joblib')

# PrÃ©dire
# (Features extraites au prÃ©alable)
prediction = model.predict(features)
print(prediction)  # â†’ 'r_holo'
```

## ğŸ“ˆ RÃ©sultats

### Performance sur Test Set (338 exemples)

| ModÃ¨le | Accuracy | F1-Score | Temps/exemple | Erreurs |
|--------|----------|----------|---------------|---------|
| **ğŸ¥‡ Random Forest** | **100.0%** | 1.000 | 0.001s | 0/338 |
| **ğŸ¥ˆ Gradient Boosting** | **100.0%** | 1.000 | 0.003s | 0/338 |
| **ğŸ¥‰ SVM Linear** | 94.7% | 0.945 | 0.001s | 18/338 |
| SVM RBF | 93.5% | 0.935 | 0.001s | 22/338 |
| Logistic Regression | 86.4% | 0.862 | 0.001s | 46/338 |

### Validation CroisÃ©e 10-Fold

| ModÃ¨le | CV Accuracy | Std | Min | Max |
|--------|-------------|-----|-----|-----|
| Random Forest | 100.0% | 0.000 | 100% | 100% |
| Gradient Boosting | 100.0% | 0.000 | 100% | 100% |
| SVM Linear | 95.6% | 0.016 | 92.9% | 97.3% |
| SVM RBF | 93.9% | 0.015 | 91.6% | 96.4% |
| Logistic Regression | 86.1% | 0.014 | 83.6% | 88.0% |

**âœ… Aucun overfitting dÃ©tectÃ©** - Performance stable train/test
**âœ… Variance faible** - Robustesse confirmÃ©e sur tous les folds

### Features UtilisÃ©es (21)

- **Morphologiques** : voyelle initiale, terminaison (-e, -s)
- **Lexicales** : dÃ©tection personne/lieu/temporel/matiÃ¨re
- **Structurelles** : longueur, ratio, prÃ©sence dÃ©terminant
- **SÃ©mantiques basiques** : catÃ©gories prÃ©dÃ©finies

### Comparaison avec LLM

| ModÃ¨le | Accuracy | Temps/exemple | CoÃ»t | Ã‰chantillon |
|--------|----------|---------------|------|-------------|
| Random Forest | 100.0% | 0.001s | Gratuit | 338 |
| Gradient Boosting | 100.0% | 0.001s | Gratuit | 338 |
| **GPT-3.5-turbo** | **95.0%** | 0.70s | $0.002/ex | 100 |
| SVM Linear | 94.7% | 0.001s | Gratuit | 338 |

**RÃ©sultats GPT-3.5-turbo** :
- Ã‰valuation few-shot (2 exemples/classe)
- 5 erreurs sur 100 exemples
- Erreurs sur cas ambigus : polysÃ©mie (peinture), multi-interprÃ©tation (carte)
- Performance remarquable mais infÃ©rieure aux modÃ¨les ensemble

## ğŸ”¬ Analyse

### Pourquoi 100% ?

Le corpus actuel est **linÃ©airement sÃ©parable** :
- âœ… Patterns morpho-syntaxiques distincts entre classes
- âœ… 150 exemples/classe bien Ã©quilibrÃ©s
- âœ… Peu d'ambiguÃ¯tÃ© sÃ©mantique
- âœ… Features basiques suffisantes (21 features)

**â†’ Les modÃ¨les ensemble (RF, GB) atteignent la perfection**

### Limites et Perspectives

**Limites actuelles :**
- Corpus trop simple (pas de cas ambigus)
- Relations bien sÃ©parÃ©es
- Pas de test sur donnÃ©es rÃ©elles

**AmÃ©liorations possibles :**
- Ajouter cas ambigus (multi-label)
- Tester sur corpus externe (Wikipedia, journaux)
- Features avancÃ©es (embeddings CamemBERT)
- Augmentation du corpus (5000+ exemples)

## ğŸ¤– Comparaison DÃ©taillÃ©e avec GPT-3.5

### MÃ©thodologie
- **ModÃ¨le** : GPT-3.5-turbo (OpenAI API)
- **Approche** : Few-shot prompting (2 exemples/classe)
- **Ã‰chantillon** : 100 exemples du test set
- **CoÃ»t** : $0.20

### RÃ©sultats

**Performance globale** :
- Accuracy : **95.0%** (5 erreurs / 100 exemples)
- Temps moyen : 0.70s par exemple
- F1-score macro : 0.96

**Classes parfaites** (12/15) :
- `r_has_causatif`, `r_has_property-1`, `r_holo`, `r_lieu>origine`
- `r_objet>matiere`, `r_own-1`, `r_processus>instr-1`, `r_processus_agent`
- `r_quantificateur`, `r_social_tie`, `r_topic`, `r_lieu`

**Classes difficiles** :
- `r_depic` : 67% (confusion lieu/topic)
- `r_processus_patient` : 78% (polysÃ©mie peinture)
- `r_product_of` : 88% (crÃ©ateur vs sujet)

### Analyse des Erreurs

Les 5 erreurs rÃ©vÃ¨lent des **ambiguÃ¯tÃ©s sÃ©mantiques lÃ©gitimes** :

1. **"la carte d'une rÃ©gion"** : `r_depic` â†’ `r_lieu`
   - AmbiguÃ¯tÃ© : reprÃ©sentation vs localisation

2. **"la peinture de la porte"** : `r_processus_patient` â†’ `r_depic`
   - PolysÃ©mie : action (peindre) vs objet (tableau)

3. **"le tableau de monet"** : `r_product_of` â†’ `r_depic`
   - Confusion : crÃ©ation vs reprÃ©sentation

### Conclusion

**Points forts de GPT-3.5** :
- âœ… Performance remarquable (95%) en few-shot
- âœ… Erreurs uniquement sur cas ambigus
- âœ… Aucune erreur grossiÃ¨re

**Avantages des modÃ¨les classiques** :
- âœ… Performance parfaite (100%)
- âœ… 700Ã— plus rapides (0.001s vs 0.70s)
- âœ… Gratuits et dÃ©ployables facilement

**Recommandation** : Pour ce corpus linÃ©airement sÃ©parable, 
Random Forest offre le meilleur compromis. GPT serait prÃ©fÃ©rable 
sur corpus rÃ©el avec forte ambiguÃ¯tÃ© contextuelle.

## ğŸ› ï¸ Technologies

- **Python 3.11**
- **scikit-learn** - ModÃ¨les ML classiques
- **pandas, numpy** - Manipulation de donnÃ©es
- **matplotlib, seaborn** - Visualisation
- **OpenAI API** - Comparaison avec ChatGPT (optionnel)
- **JeuxDeMots API** - Enrichissement sÃ©mantique (en cours)

## ğŸ“š Ressources

- **Corpus** : 2250 constructions "A de B" (150/classe)
- **JeuxDeMots** : http://www.jeuxdemots.org/
- **Article de rÃ©fÃ©rence** : 
  - *Extraction automatique de rÃ¨gles pour la dÃ©termination de types de relations sÃ©mantiques dans les constructions gÃ©nitives en franÃ§ais*
  - H. Guenoune, M. Lafourcade (LIRMM, 2024)
  - [Lien PDF](https://pfia2024.univ-lr.fr/assets/files/Conf%C3%A9rence-IC/IC_2024_paper_20.pdf)

## ğŸ‘¥ Contributeurs

- **Rivals Leonard** - Development & ML
- **Bazireau** - Research & Analysis

## ğŸ“ Licence

_Ã€ dÃ©finir_

## ğŸ”„ Statut du Projet

âœ… **Phase 1 : ModÃ¨les Baseline ComplÃ©tÃ©e**

### âœ… Ã‰tapes rÃ©alisÃ©es
- [x] Architecture du projet dÃ©finie
- [x] Structure de dossiers crÃ©Ã©e
- [x] PrÃ©processing du corpus (2250 exemples)
- [x] Extraction de features (21 features numÃ©riques)
- [x] Data splitting stratifiÃ© (70/15/15)
- [x] 5 modÃ¨les baseline entraÃ®nÃ©s
- [x] Ã‰valuation sur test set
- [x] Validation croisÃ©e 10-fold
- [x] Matrices de confusion gÃ©nÃ©rÃ©es
- [x] Scripts de comparaison ChatGPT prÃªts

### âœ… RÃ©cemment complÃ©tÃ©
- [x] Comparaison avec ChatGPT (GPT-3.5-turbo : 95%)
- [x] Graphiques comparatifs gÃ©nÃ©rÃ©s
- [x] Analyse des erreurs LLM

### ğŸš§ En cours
- [ ] Analyse de l'importance des features
- [ ] Test GPT-4 (optionnel)
- [ ] IntÃ©gration API JeuxDeMots pour enrichissement

### ğŸ“‹ Ã€ venir
- [ ] ModÃ¨les Deep Learning (CamemBERT)
- [ ] Test sur corpus externe
- [ ] Gestion des cas ambigus (multi-label)
- [ ] Interface de dÃ©monstration
- [ ] Rapport final et documentation

## ğŸ“Š ReproductibilitÃ©

Tous les rÃ©sultats sont reproductibles avec `random_state=42` :
```bash
# Reproduire les rÃ©sultats exacts
python run_preprocessing.py
python run_feature_extraction.py
python run_train_baseline.py
python run_evaluate_test.py
```

Les modÃ¨les entraÃ®nÃ©s sont sauvegardÃ©s dans `models/baseline/`.

---

**DerniÃ¨re mise Ã  jour** : Novembre 2024
**Version** : 1.0.0 - Baseline Models ComplÃ¨te