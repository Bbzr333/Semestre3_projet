# Pipeline de Classification des Relations S√©mantiques

Classification automatique des relations s√©mantiques dans les constructions g√©nitives fran√ßaises ("A de B").

## üìã Description

Ce projet d√©veloppe un syst√®me capable d'identifier automatiquement le type de relation s√©mantique entre deux noms dans une construction g√©nitive fran√ßaise.

**Exemples** : 
- "la porte de la maison" ‚Üí **r_holo** (Partie-Tout)
- "le livre de Marie" ‚Üí **r_own-1** (Possession)
- "le train de Paris" ‚Üí **r_lieu>origine** (Origine)

## üéØ Objectifs

- ‚úÖ Classifier 15 types de relations s√©mantiques
- ‚úÖ Comparer diff√©rentes approches (ML classique, deep learning)
- ‚úÖ √âvaluer les performances face aux LLM
- ‚öôÔ∏è Exploiter la ressource JeuxDeMots pour l'enrichissement

## üóÇÔ∏è Structure du Projet

```
.
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Corpus initial (2250 exemples)
‚îÇ   ‚îî‚îÄ‚îÄ processed/              # Donn√©es pr√©trait√©es (train/val/test)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/          # Nettoyage et normalisation
‚îÇ   ‚îú‚îÄ‚îÄ features/               # Extraction de features
‚îÇ   ‚îú‚îÄ‚îÄ models/                 # Mod√®les de classification
‚îÇ   ‚îî‚îÄ‚îÄ evaluation/             # M√©triques et analyse
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ baseline/               # Mod√®les entra√Æn√©s (.joblib)
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ test_results.csv        # R√©sultats sur test set
‚îÇ   ‚îú‚îÄ‚îÄ cross_validation_detailed.csv
‚îÇ   ‚îî‚îÄ‚îÄ plots/                  # Visualisations
‚îú‚îÄ‚îÄ run_preprocessing.py        # Pr√©traitement du corpus
‚îú‚îÄ‚îÄ run_feature_extraction.py  # Extraction de features
‚îú‚îÄ‚îÄ run_train_baseline.py      # Entra√Ænement des mod√®les
‚îú‚îÄ‚îÄ run_evaluate_test.py       # √âvaluation sur test set
‚îú‚îÄ‚îÄ run_cross_validation.py    # Validation crois√©e 10-fold
‚îî‚îÄ‚îÄ run_chatgpt_simple.py      # Comparaison avec ChatGPT
```

## üöÄ Installation

```bash
# Cloner le d√©p√¥t
git clone https://github.com/Bbzr333/Semestre3_projet
cd Langage_naturel

# Cr√©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Installer les d√©pendances
pip install -r requirements.txt
```

## üìä Types de Relations (15)

| Code | Description | Exemple |
|------|-------------|---------|
| `r_has_causatif` | Relation de cause | "les retards de la pluie" |
| `r_has_property-1` | Propri√©t√© | "la g√©n√©rosit√© du b√©n√©vole" |
| `r_objet>matiere` | Mati√®re | "une table de bois" |
| `r_lieu>origine` | Origine g√©ographique | "le vin de Bordeaux" |
| `r_topic` | Th√®me/Sujet | "un livre d'histoire" |
| `r_depic` | Repr√©sentation | "le portrait de Marie" |
| `r_holo` | Partie-Tout | "la porte de la maison" |
| `r_lieu` | Localisation | "les gens de la ville" |
| `r_processus_agent` | Agent d'un processus | "le discours du pr√©sident" |
| `r_processus_patient` | Patient d'un processus | "la sculpture du bois" |
| `r_processus>instr-1` | Instrument | "le marteau de forgeron" |
| `r_own-1` | Possession | "le livre de Marie" |
| `r_quantificateur` | Quantit√© | "un kilo de pommes" |
| `r_social_tie` | Lien social | "l'ami de Pierre" |
| `r_product_of` | Produit de | "le tableau de Picasso" |

## üîß Utilisation

### Pipeline Complet

```bash
# 1. Pr√©traitement du corpus
python run_preprocessing.py
# ‚Üí G√©n√®re: data/processed/corpus_preprocessed.csv

# 2. Extraction de features
python run_feature_extraction.py
# ‚Üí G√©n√®re: data/processed/{train,val,test}.csv

# 3. Entra√Ænement des mod√®les
python run_train_baseline.py
# ‚Üí G√©n√®re: models/baseline/*.joblib

# 4. √âvaluation sur test set
python run_evaluate_test.py
# ‚Üí G√©n√®re: results/test_results.csv + matrices de confusion

# 5. Validation crois√©e
python run_cross_validation.py
# ‚Üí G√©n√®re: results/cross_validation_detailed.csv

# 6. Comparaison avec ChatGPT (optionnel)
export OPENAI_API_KEY='sk-...'
python run_chatgpt_simple.py
# ‚Üí Co√ªt: ~$0.10 pour 50 exemples
```

### Utilisation du Meilleur Mod√®le

```python
from src.models.baseline_models import BaselineClassifier
import pandas as pd

# Charger le mod√®le
model = BaselineClassifier.load('models/baseline/random_forest.joblib')

# Pr√©dire
# (Features extraites au pr√©alable)
prediction = model.predict(features)
print(prediction)  # ‚Üí 'r_holo'
```

## üìà R√©sultats

### Performance sur Test Set (338 exemples)

| Mod√®le | Accuracy | F1-Score | Temps/exemple | Erreurs |
|--------|----------|----------|---------------|---------|
| **ü•á Random Forest** | **100.0%** | 1.000 | 0.001s | 0/338 |
| **ü•à Gradient Boosting** | **100.0%** | 1.000 | 0.003s | 0/338 |
| **ü•â SVM Linear** | 94.7% | 0.945 | 0.001s | 18/338 |
| SVM RBF | 93.5% | 0.935 | 0.001s | 22/338 |
| Logistic Regression | 86.4% | 0.862 | 0.001s | 46/338 |

### Validation Crois√©e 10-Fold

| Mod√®le | CV Accuracy | Std | Min | Max |
|--------|-------------|-----|-----|-----|
| Random Forest | 100.0% | 0.000 | 100% | 100% |
| Gradient Boosting | 100.0% | 0.000 | 100% | 100% |
| SVM Linear | 95.6% | 0.016 | 92.9% | 97.3% |
| SVM RBF | 93.9% | 0.015 | 91.6% | 96.4% |
| Logistic Regression | 86.1% | 0.014 | 83.6% | 88.0% |

**‚úÖ Aucun overfitting d√©tect√©** - Performance stable train/test
**‚úÖ Variance faible** - Robustesse confirm√©e sur tous les folds

### Features Utilis√©es (21)

- **Morphologiques** : voyelle initiale, terminaison (-e, -s)
- **Lexicales** : d√©tection personne/lieu/temporel/mati√®re
- **Structurelles** : longueur, ratio, pr√©sence d√©terminant
- **S√©mantiques basiques** : cat√©gories pr√©d√©finies

### Comparaison avec LLM (√† venir)

| Mod√®le | Accuracy | Temps/exemple | Co√ªt |
|--------|----------|---------------|------|
| Random Forest | 100.0% | 0.001s | Gratuit |
| GPT-3.5-turbo | ~85-90%* | 2.5s | $0.002/ex |
| GPT-4 | ~95-98%* | 3s | $0.12/ex |

*Estimation - Tests en cours

## üî¨ Analyse

### Pourquoi 100% ?

Le corpus actuel est **lin√©airement s√©parable** :
- ‚úÖ Patterns morpho-syntaxiques distincts entre classes
- ‚úÖ 150 exemples/classe bien √©quilibr√©s
- ‚úÖ Peu d'ambigu√Øt√© s√©mantique
- ‚úÖ Features basiques suffisantes (21 features)

**‚Üí Les mod√®les ensemble (RF, GB) atteignent la perfection**

### Limites et Perspectives

**Limites actuelles :**
- Corpus trop simple (pas de cas ambigus)
- Relations bien s√©par√©es
- Pas de test sur donn√©es r√©elles

**Am√©liorations possibles :**
- Ajouter cas ambigus (multi-label)
- Tester sur corpus externe (Wikipedia, journaux)
- Features avanc√©es (embeddings CamemBERT)
- Augmentation du corpus (5000+ exemples)

## üõ†Ô∏è Technologies

- **Python 3.11**
- **scikit-learn** - Mod√®les ML classiques
- **pandas, numpy** - Manipulation de donn√©es
- **matplotlib, seaborn** - Visualisation
- **OpenAI API** - Comparaison avec ChatGPT (optionnel)
- **JeuxDeMots API** - Enrichissement s√©mantique (en cours)

## üìö Ressources

- **Corpus** : 2250 constructions "A de B" (150/classe)
- **JeuxDeMots** : http://www.jeuxdemots.org/
- **Article de r√©f√©rence** : 
  - *Extraction automatique de r√®gles pour la d√©termination de types de relations s√©mantiques dans les constructions g√©nitives en fran√ßais*
  - H. Guenoune, M. Lafourcade (LIRMM, 2024)
  - [Lien PDF](https://pfia2024.univ-lr.fr/assets/files/Conf%C3%A9rence-IC/IC_2024_paper_20.pdf)

## üë• Contributeurs

- **Rivals Leonard** - Development & ML
- **Bazireau** - Research & Analysis

## üìù Licence

_√Ä d√©finir_

## üîÑ Statut du Projet

‚úÖ **Phase 1 : Mod√®les Baseline Compl√©t√©e**

### ‚úÖ √âtapes r√©alis√©es
- [x] Architecture du projet d√©finie
- [x] Structure de dossiers cr√©√©e
- [x] Pr√©processing du corpus (2250 exemples)
- [x] Extraction de features (21 features num√©riques)
- [x] Data splitting stratifi√© (70/15/15)
- [x] 5 mod√®les baseline entra√Æn√©s
- [x] √âvaluation sur test set
- [x] Validation crois√©e 10-fold
- [x] Matrices de confusion g√©n√©r√©es
- [x] Scripts de comparaison ChatGPT pr√™ts

### üöß En cours
- [ ] Comparaison avec ChatGPT (GPT-3.5/GPT-4)
- [ ] Analyse de l'importance des features
- [ ] Int√©gration API JeuxDeMots pour enrichissement

### üìã √Ä venir
- [ ] Mod√®les Deep Learning (CamemBERT)
- [ ] Test sur corpus externe
- [ ] Gestion des cas ambigus (multi-label)
- [ ] Interface de d√©monstration
- [ ] Rapport final et documentation

## üìä Reproductibilit√©

Tous les r√©sultats sont reproductibles avec `random_state=42` :
```bash
# Reproduire les r√©sultats exacts
python run_preprocessing.py
python run_feature_extraction.py
python run_train_baseline.py
python run_evaluate_test.py
```

Les mod√®les entra√Æn√©s sont sauvegard√©s dans `models/baseline/`.

---

**Derni√®re mise √† jour** : Novembre 2024
**Version** : 1.0.0 - Baseline Models Compl√®te