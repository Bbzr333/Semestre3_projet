"""
Entra√Ænement des mod√®les baseline
Version corrig√©e avec filtrage robuste des features
"""

import pandas as pd
import sys
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')
import numpy as np

sys.path.append('src')

from src.models.baseline_models import BaselineClassifier
from src.evaluation.evaluator import ModelEvaluator

def main():
    print("üöÄ Entra√Ænement des mod√®les baseline")
    print("=" * 60)
    
    # Chargement des donn√©es
    train = pd.read_csv('data/processed/train.csv')
    val = pd.read_csv('data/processed/val.csv')
    
    # ========== CORRECTION : Filtrage robuste des features ==========
    # On exclut explicitement les colonnes non-num√©riques
    excluded_cols = ['phrase_originale', 'nom1_lemme', 'nom2_lemme', 'type_jdm', 'definitude']
    
    # S√©lection automatique des colonnes num√©riques uniquement
    numeric_cols = train.select_dtypes(include=['int64', 'float64', 'int32', 'float32', 'bool']).columns.tolist()
    feature_cols = [col for col in numeric_cols if col not in excluded_cols]
    
    # Diagnostic des colonnes
    print(f"\nüîç Diagnostic des colonnes:")
    print(f"  Total colonnes: {len(train.columns)}")
    print(f"  Colonnes num√©riques: {len(numeric_cols)}")
    print(f"  Features s√©lectionn√©es: {len(feature_cols)}")
    
    # Afficher quelques exemples de features
    print(f"\nüìä Exemples de features:")
    for i, col in enumerate(feature_cols[:8]):
        print(f"    {i+1}. {col}")
    if len(feature_cols) > 8:
        print(f"    ... et {len(feature_cols) - 8} autres")
    
    X_train = train[feature_cols]
    y_train = train['type_jdm']
    X_val = val[feature_cols]
    y_val = val['type_jdm']

    # === NETTOYAGE DES DONN√âES ===
    constant_cols = X_train.columns[X_train.std() == 0].tolist()
    if constant_cols:
        print(f"  üóëÔ∏è  {len(constant_cols)} colonnes constantes supprim√©es")
        X_train = X_train.drop(columns=constant_cols)
        X_val = X_val.drop(columns=constant_cols)
    X_train = X_train.replace([np.inf, -np.inf], np.nan).fillna(0)
    X_val = X_val.replace([np.inf, -np.inf], np.nan).fillna(0)
    print(f"  ‚úì Features finales: {X_train.shape[1]}")
    # ==============================
    
    # V√©rification et traitement des valeurs manquantes
    if X_train.isnull().any().any():
        print(f"\n‚ö†Ô∏è  Valeurs manquantes d√©tect√©es!")
        missing_summary = X_train.isnull().sum()[X_train.isnull().sum() > 0]
        print(missing_summary)
        X_train = X_train.fillna(0)
        X_val = X_val.fillna(0)
        print(f"‚úì Valeurs manquantes remplac√©es par 0")
    
    # V√©rification des valeurs infinies
    if not pd.api.types.is_numeric_dtype(X_train.values.flatten()):
        print(f"‚ö†Ô∏è  Attention: types non-num√©riques d√©tect√©s!")
        print(X_train.dtypes)
    
    print(f"\n‚úì Train: {len(X_train)} exemples, {len(feature_cols)} features")
    print(f"‚úì Val: {len(X_val)} exemples")
    print(f"‚úì Classes: {y_train.nunique()}")
    
    # ============================================================
    
    # Entra√Ænement de tous les mod√®les
    models_dir = Path('models/baseline')
    models_dir.mkdir(parents=True, exist_ok=True)
    
    results_dir = Path('results')
    results_dir.mkdir(parents=True, exist_ok=True)
    
    results = {}
    
    for model_name in BaselineClassifier.MODELS.keys():
        print(f"\nüìä Entra√Ænement: {model_name}")
        print("-" * 60)
        
        try:
            # Train
            classifier = BaselineClassifier(model_name=model_name)
            classifier.train(X_train, y_train)
            
            print(f"  ‚úì Temps d'entra√Ænement: {classifier.training_history['training_time_seconds']:.2f}s")
            
            # Eval sur validation
            evaluator = ModelEvaluator()
            metrics = evaluator.evaluate(classifier, X_val, y_val)
            
            print(f"  ‚úì Accuracy: {metrics['accuracy']:.3f}")
            print(f"  ‚úì F1-score (macro): {metrics['f1_macro']:.3f}")
            print(f"  ‚úì Precision (macro): {metrics['precision_macro']:.3f}")
            print(f"  ‚úì Recall (macro): {metrics['recall_macro']:.3f}")
            
            # Sauvegarde du mod√®le
            model_path = models_dir / f'{model_name}.joblib'
            classifier.save(model_path)
            print(f"  üíæ Mod√®le sauvegard√©: {model_path}")
            
            results[model_name] = {
                'accuracy': metrics['accuracy'],
                'f1_macro': metrics['f1_macro'],
                'precision_macro': metrics['precision_macro'],
                'recall_macro': metrics['recall_macro'],
                'training_time': classifier.training_history['training_time_seconds']
            }
            
        except Exception as e:
            print(f"  ‚ùå Erreur: {e}")
            results[model_name] = {
                'accuracy': 0.0,
                'f1_macro': 0.0,
                'precision_macro': 0.0,
                'recall_macro': 0.0,
                'training_time': 0.0,
                'error': str(e)
            }
    
    # Comparaison des mod√®les
    print("\n" + "=" * 60)
    print("üìä COMPARAISON DES MOD√àLES")
    print("=" * 60)
    
    df_results = pd.DataFrame(results).T
    df_results = df_results.sort_values('accuracy', ascending=False)
    
    print("\nüèÜ Classement par Accuracy:")
    print(df_results[['accuracy', 'f1_macro', 'precision_macro', 'recall_macro', 'training_time']].to_string())
    
    # Sauvegarde des r√©sultats
    results_path = results_dir / 'baseline_comparison.csv'
    df_results.to_csv(results_path)
    print(f"\nüíæ R√©sultats sauvegard√©s: {results_path}")
    
    # Meilleur mod√®le
    best_model = df_results.index[0]
    best_acc = df_results.iloc[0]['accuracy']
    print(f"\nü•á Meilleur mod√®le: {best_model} (Accuracy: {best_acc:.3f})")
    
    print("\n" + "=" * 60)
    print("‚úÖ ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS!")
    print("=" * 60)

if __name__ == '__main__':
    main()